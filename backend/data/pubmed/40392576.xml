<?xml version="1.0" ?>
<!DOCTYPE PubmedArticleSet PUBLIC "-//NLM//DTD PubMedArticle, 1st January 2025//EN" "https://dtd.nlm.nih.gov/ncbi/pubmed/out/pubmed_250101.dtd">
<PubmedArticleSet>
<PubmedArticle><MedlineCitation Status="MEDLINE" Owner="NLM" IndexingMethod="Automated"><PMID Version="1">40392576</PMID><DateCompleted><Year>2025</Year><Month>05</Month><Day>20</Day></DateCompleted><DateRevised><Year>2025</Year><Month>05</Month><Day>20</Day></DateRevised><Article PubModel="Electronic"><Journal><ISSN IssnType="Electronic">1438-8871</ISSN><JournalIssue CitedMedium="Internet"><Volume>27</Volume><PubDate><Year>2025</Year><Month>May</Month><Day>20</Day></PubDate></JournalIssue><Title>Journal of medical Internet research</Title><ISOAbbreviation>J Med Internet Res</ISOAbbreviation></Journal><ArticleTitle>Assessing the Accuracy and Reliability of Large Language Models in Psychiatry Using Standardized Multiple-Choice Questions: Cross-Sectional Study.</ArticleTitle><Pagination><StartPage>e69910</StartPage><MedlinePgn>e69910</MedlinePgn></Pagination><ELocationID EIdType="doi" ValidYN="Y">10.2196/69910</ELocationID><Abstract><AbstractText Label="BACKGROUND" NlmCategory="BACKGROUND">Large language models (LLMs), such as OpenAI's GPT-3.5, GPT-4, and GPT-4o, have garnered early and significant enthusiasm for their potential applications within mental health, ranging from documentation support to chat-bot therapy. Understanding the accuracy and reliability of the psychiatric "knowledge" stored within the parameters of these models and developing measures of confidence in their responses (ie, the likelihood that an LLM response is accurate) are crucial for the safe and effective integration of these tools into mental health settings.</AbstractText><AbstractText Label="OBJECTIVE" NlmCategory="OBJECTIVE">This study aimed to assess the accuracy, reliability, and predictors of accuracy of GPT-3.5 (175 billion parameters), GPT-4 (approximately 1.8 trillion parameters), and GPT-4o (an optimized version of GPT-4 with unknown parameters) with standardized psychiatry multiple-choice questions (MCQs).</AbstractText><AbstractText Label="METHODS" NlmCategory="METHODS">A cross-sectional study was conducted where 3 commonly available, commercial LLMs (GPT-3.5, GPT-4, and GPT-4o) were tested for their ability to provide answers to single-answer MCQs (N=150) extracted from the Psychiatry Test Preparation and Review Manual. Each model generated answers to every MCQ 10 times. We evaluated the accuracy and reliability of the answers and sought predictors of answer accuracy. Our primary outcome was the proportion of questions answered correctly by each LLM (accuracy). Secondary measures were (1) response consistency to MCQs across 10 trials (reliability), (2) the correlation between MCQ answer accuracy and response consistency, and (3) the correlation between MCQ answer accuracy and model self-reported confidence.</AbstractText><AbstractText Label="RESULTS" NlmCategory="RESULTS">On the first attempt, GPT-3.5 answered 58.0% (87/150) of MCQs correctly, while GPT-4 and GPT-4o answered 84.0% (126/150) and 87.3% (131/150) correctly, respectively. GPT-4 and GPT-4o showed no difference in performance (P=.51), but they significantly outperformed GPT-3.5 (P&lt;.001). GPT-3.5 exhibited less response consistency on average compared to the other models (P&lt;.001). MCQ response consistency was positively correlated with MCQ accuracy across all models (r=0.340, 0.682, and 0.590 for GPT-3.5, GPT-4, and GPT-4o, respectively; all P&lt;.001), whereas model self-reported confidence showed no correlation with accuracy in the models, except for GPT-3.5, where self-reported confidence was weakly inversely correlated with accuracy (P&lt;.001).</AbstractText><AbstractText Label="CONCLUSIONS" NlmCategory="CONCLUSIONS">To our knowledge, this is the first comprehensive evaluation of the general psychiatric knowledge encoded in commercially available LLMs and the first study to assess their reliability and identify predictors of response accuracy within medical domains. The findings suggest that GPT-4 and GPT-4o encode accurate and reliable general psychiatric knowledge and that methods, such as repeated prompting, may provide a measure of LLM response confidence. This work supports the potential of LLMs in mental health settings and motivates further research to assess their performance in more open-ended clinical contexts.</AbstractText><CopyrightInformation>&#xa9;Kaitlin Hanss, Karthik V Sarma, Anne L Glowinski, Andrew Krystal, Ramotse Saunders, Andrew Halls, Sasha Gorrell, Erin Reilly. Originally published in the Journal of Medical Internet Research (https://www.jmir.org), 20.05.2025.</CopyrightInformation></Abstract><AuthorList CompleteYN="Y"><Author ValidYN="Y"><LastName>Hanss</LastName><ForeName>Kaitlin</ForeName><Initials>K</Initials><Identifier Source="ORCID">0000-0003-1462-4335</Identifier><AffiliationInfo><Affiliation>Department of Psychiatry and Behavioral Sciences, University of California, San Francisco, San Francisco, CA, United States.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Sarma</LastName><ForeName>Karthik V</ForeName><Initials>KV</Initials><Identifier Source="ORCID">0000-0002-7442-9526</Identifier><AffiliationInfo><Affiliation>Department of Psychiatry and Behavioral Sciences, University of California, San Francisco, San Francisco, CA, United States.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Glowinski</LastName><ForeName>Anne L</ForeName><Initials>AL</Initials><Identifier Source="ORCID">0000-0002-0690-9560</Identifier><AffiliationInfo><Affiliation>Department of Psychiatry and Behavioral Sciences, University of California, San Francisco, San Francisco, CA, United States.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Krystal</LastName><ForeName>Andrew</ForeName><Initials>A</Initials><Identifier Source="ORCID">0000-0002-6702-781X</Identifier><AffiliationInfo><Affiliation>Department of Psychiatry and Behavioral Sciences, University of California, San Francisco, San Francisco, CA, United States.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Saunders</LastName><ForeName>Ramotse</ForeName><Initials>R</Initials><Identifier Source="ORCID">0000-0002-6735-4482</Identifier><AffiliationInfo><Affiliation>Department of Psychiatry and Behavioral Sciences, University of California, San Francisco, San Francisco, CA, United States.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Halls</LastName><ForeName>Andrew</ForeName><Initials>A</Initials><Identifier Source="ORCID">0000-0002-8943-5822</Identifier><AffiliationInfo><Affiliation>Department of Psychiatry and Behavioral Sciences, University of California, San Francisco, San Francisco, CA, United States.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Gorrell</LastName><ForeName>Sasha</ForeName><Initials>S</Initials><Identifier Source="ORCID">0000-0002-8861-8547</Identifier><AffiliationInfo><Affiliation>Department of Psychiatry and Behavioral Sciences, University of California, San Francisco, San Francisco, CA, United States.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Reilly</LastName><ForeName>Erin</ForeName><Initials>E</Initials><Identifier Source="ORCID">0000-0001-9269-0747</Identifier><AffiliationInfo><Affiliation>Department of Psychiatry and Behavioral Sciences, University of California, San Francisco, San Francisco, CA, United States.</Affiliation></AffiliationInfo></Author></AuthorList><Language>eng</Language><PublicationTypeList><PublicationType UI="D016428">Journal Article</PublicationType></PublicationTypeList><ArticleDate DateType="Electronic"><Year>2025</Year><Month>05</Month><Day>20</Day></ArticleDate></Article><MedlineJournalInfo><Country>Canada</Country><MedlineTA>J Med Internet Res</MedlineTA><NlmUniqueID>100959882</NlmUniqueID><ISSNLinking>1438-8871</ISSNLinking></MedlineJournalInfo><CitationSubset>IM</CitationSubset><MeshHeadingList><MeshHeading><DescriptorName UI="D003430" MajorTopicYN="N">Cross-Sectional Studies</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D006801" MajorTopicYN="N">Humans</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D015203" MajorTopicYN="N">Reproducibility of Results</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D011570" MajorTopicYN="Y">Psychiatry</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D007802" MajorTopicYN="Y">Language</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D011795" MajorTopicYN="N">Surveys and Questionnaires</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D000098342" MajorTopicYN="N">Large Language Models</DescriptorName></MeshHeading></MeshHeadingList><KeywordList Owner="NOTNLM"><Keyword MajorTopicYN="N">AI</Keyword><Keyword MajorTopicYN="N">artificial intelligence</Keyword><Keyword MajorTopicYN="N">digital mental health</Keyword><Keyword MajorTopicYN="N">knowledge assessment</Keyword><Keyword MajorTopicYN="N">mental health</Keyword></KeywordList></MedlineCitation><PubmedData><History><PubMedPubDate PubStatus="received"><Year>2024</Year><Month>12</Month><Day>11</Day></PubMedPubDate><PubMedPubDate PubStatus="accepted"><Year>2025</Year><Month>4</Month><Day>28</Day></PubMedPubDate><PubMedPubDate PubStatus="revised"><Year>2025</Year><Month>3</Month><Day>16</Day></PubMedPubDate><PubMedPubDate PubStatus="medline"><Year>2025</Year><Month>5</Month><Day>20</Day><Hour>18</Hour><Minute>29</Minute></PubMedPubDate><PubMedPubDate PubStatus="pubmed"><Year>2025</Year><Month>5</Month><Day>20</Day><Hour>17</Hour><Minute>6</Minute></PubMedPubDate><PubMedPubDate PubStatus="entrez"><Year>2025</Year><Month>5</Month><Day>20</Day><Hour>11</Hour><Minute>52</Minute></PubMedPubDate></History><PublicationStatus>epublish</PublicationStatus><ArticleIdList><ArticleId IdType="pubmed">40392576</ArticleId><ArticleId IdType="doi">10.2196/69910</ArticleId><ArticleId IdType="pii">v27i1e69910</ArticleId></ArticleIdList></PubmedData></PubmedArticle></PubmedArticleSet>